{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7131822e-45de-48ca-b6ba-e563d4151ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8991e7ab-9222-49eb-a933-103cbfee707e",
   "metadata": {},
   "source": [
    "# Step 1: Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de9d9d1-a34a-46a2-b7cd-59e652a060dc",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fdcd1771-44c5-471e-a811-315f5348428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('HateSpeech_Kenya.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1307979a-2d9c-47af-981e-b448191a4844",
   "metadata": {},
   "source": [
    "Display basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9eb0007b-9651-4116-aac1-85cc728023ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (48076, 5)\n",
      "Columns: ['hate_speech', 'offensive_language', 'neither', 'Class', 'Tweet']\n",
      "   hate_speech  offensive_language  neither  Class  \\\n",
      "0            0                   0        3      0   \n",
      "1            0                   0        3      0   \n",
      "2            0                   0        3      0   \n",
      "3            0                   0        3      0   \n",
      "4            0                   0        3      0   \n",
      "\n",
      "                                               Tweet  \n",
      "0  ['The political elite are in desperation. Ordi...  \n",
      "1  [\"Am just curious the only people who are call...  \n",
      "2  ['USERNAME_3 the area politicians are the one ...  \n",
      "3  ['War expected in Nakuru if something is not d...  \n",
      "4  ['USERNAME_4 tells kikuyus activists that they...  \n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bcd630-40be-49cf-9e64-6757c45dd053",
   "metadata": {},
   "source": [
    "Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "10d29cf1-75b9-4897-9690-d5fd426eac76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n",
      "hate_speech           0\n",
      "offensive_language    0\n",
      "neither               0\n",
      "Class                 0\n",
      "Tweet                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a081f5-cbfc-4a44-acd3-7d8c56377b47",
   "metadata": {},
   "source": [
    "Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "eee48ad1-724e-4e7f-89c7-9e4efe743ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution:\n",
      "Class\n",
      "0    36352\n",
      "1     8543\n",
      "2     3181\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_counts = df['Class'].value_counts()\n",
    "print(\"\\nClass distribution:\")\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209cfa14-b78f-4be0-a3f3-4c1880d4fb55",
   "metadata": {},
   "source": [
    "Map class values to readable labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3cf63baa-9fcc-451c-8880-a16f2b1adca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    0: \"Neither\",\n",
    "    1: \"Offensive\",\n",
    "    2: \"Hate Speech\"\n",
    "}\n",
    "\n",
    "df['class_label'] = df['Class'].map(class_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a3f0a7-9305-4efa-b5cc-21f5c77e67c4",
   "metadata": {},
   "source": [
    "Visualize class distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "19f957a4-9d57-4a91-a506-00616bc3f3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='class_label', data=df)\n",
    "plt.title('Distribution of Classes')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Class')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_distribution.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c95365-8f5c-43d7-bd0f-98135913c16e",
   "metadata": {},
   "source": [
    "# Step 2: Text Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0520fd88-7012-461b-8458-b1d270899492",
   "metadata": {},
   "source": [
    "Download NLTK resources if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dccb2bd1-8d52-44fd-946f-547d50ce67b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('punkt_tab')\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('wordnet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24879841-a80b-4ed2-8534-c563c0ab6f7e",
   "metadata": {},
   "source": [
    "Initialize lemmatizer and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6422a1bd-5897-4ae9-8836-0d495e659d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and preprocess text data\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove the list formatting if present (specific to this dataset)\n",
    "    text = re.sub(r\"^\\['|'\\]$\", \"\", text)\n",
    "    text = text.replace(\"\\\\\\\"\", \"\")\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    \n",
    "    # Remove usernames (specific to this dataset)\n",
    "    text = re.sub(r'USERNAME_\\d+', '', text)\n",
    "    \n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and lemmatize\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words and len(token) > 2]\n",
    "    \n",
    "    # Rejoin tokens\n",
    "    cleaned_text = ' '.join(cleaned_tokens)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d821c9c-411c-417a-83a0-3a33d053f564",
   "metadata": {},
   "source": [
    "Apply preprocessing to the Tweet column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "386cd1f9-f560-4357-af53-d7de11880e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_text'] = df['Tweet'].apply(preprocess_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da01fde-3568-4092-992b-3756ea0608c5",
   "metadata": {},
   "source": [
    "Compare original and processed text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9e8d2fd9-7412-4b36-aa2c-65b999a4f336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original vs Processed text samples:\n",
      "Original: ['The political elite are in desperation. Ordinary kalenjins are suspicious of kikuyu community']\n",
      "Processed: political elite desperation ordinary kalenjins suspicious kikuyu community\n",
      "\n",
      "Original: [\"Am just curious the only people who are calling him old and mad are Kikuyus and not Kalenjins and that's a good sign USERNAME_1 USERNAME_2\"]\n",
      "Processed: curious people calling old mad kikuyus kalenjins thats good sign username_ username_\n",
      "\n",
      "Original: ['USERNAME_3 the area politicians are the one to blame coz they r insiting local students n villagers to attack non kalenjins students']\n",
      "Processed: username_ area politician one blame coz insiting local student villager attack non kalenjins student\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOriginal vs Processed text samples:\")\n",
    "for i in range(3):\n",
    "    print(f\"Original: {df['Tweet'].iloc[i]}\")\n",
    "    print(f\"Processed: {df['processed_text'].iloc[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0d4093-ae7d-430d-b8e3-bf57835b962e",
   "metadata": {},
   "source": [
    "# Step 3: Feature Engineering and Data Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a8a7232d-4e74-4478-87d8-2e8df6c69781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Creating features and splitting data...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 3: Creating features and splitting data...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456fc44c-d2ba-4f02-880e-1e38e6be0b88",
   "metadata": {},
   "source": [
    "Check for and remove empty processed texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "eed3b4cc-de45-49c0-9f9f-8a7e1b6109eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty texts after preprocessing: 9\n"
     ]
    }
   ],
   "source": [
    "empty_texts = df['processed_text'].str.strip() == ''\n",
    "print(f\"Number of empty texts after preprocessing: {sum(empty_texts)}\")\n",
    "df = df[~empty_texts].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beb4a02-3c34-4d1b-939b-70e39ae30742",
   "metadata": {},
   "source": [
    "Split data into features and target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5235f6fd-acc9-40ba-8470-a873732480a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['processed_text']\n",
    "y = df['Class']  # Using the numerical class labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f58af39-e6a3-4d2e-b3c8-5f5ded8a1016",
   "metadata": {},
   "source": [
    "Split into training and testing sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "50152cd3-e14e-47b3-a1a5-483b8948a225",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3243b3d3-53ab-4fc1-9171-5659157bbe1a",
   "metadata": {},
   "source": [
    "Convert text to numerical features using TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "20708ab4-e6a2-4b0f-8d38-c0dcb9c5e5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (38453, 5000)\n",
      "Testing features shape: (9614, 5000)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, min_df=5)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"Training features shape: {X_train_tfidf.shape}\")\n",
    "print(f\"Testing features shape: {X_test_tfidf.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f167ce4b-6577-44a1-bfbb-2cbe9c7bc252",
   "metadata": {},
   "source": [
    "Save key vocabulary words for later reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a0eb1372-9838-4b4b-adbb-c2ab6e07e240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top TF-IDF vocabulary words:\n",
      "['ababu', 'ability', 'able', 'abroad', 'absolute', 'absolutely', 'abt', 'abuse', 'abused', 'abusing', 'abusive', 'academic', 'accent', 'accept', 'acceptable', 'accepted', 'accepting', 'access', 'accident', 'according']\n"
     ]
    }
   ],
   "source": [
    "top_words = pd.DataFrame(tfidf_vectorizer.vocabulary_.items(), columns=['Word', 'Index'])\n",
    "top_words = top_words.sort_values('Index').head(20)\n",
    "print(\"\\nTop TF-IDF vocabulary words:\")\n",
    "print(top_words['Word'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9906e8aa-a74f-4422-8fd3-97d819213ed4",
   "metadata": {},
   "source": [
    "# Step 4: Model Building and Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "622e96b2-ea24-4552-803c-9d3488fb1718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Building and evaluating models...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 4: Building and evaluating models...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dfcc40-7b04-41c6-8a27-f2f1aa7435de",
   "metadata": {},
   "source": [
    "Define models to test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "95ad86af-e90f-437b-9687-19a4dae60b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, C=1, class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "    'Linear SVM': LinearSVC(C=1, class_weight='balanced', max_iter=10000),\n",
    "    'Multinomial NB': MultinomialNB(alpha=0.1)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a504dd4-389d-46d3-940a-57f0c5d3c332",
   "metadata": {},
   "source": [
    "Train and evaluate each model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f90cb-883d-423a-b2a1-e0d10e75ff57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.6158\n",
      "Training time: 2.70 seconds\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neither       0.88      0.66      0.76      7269\n",
      "   Offensive       0.30      0.42      0.35      1709\n",
      " Hate Speech       0.23      0.61      0.33       636\n",
      "\n",
      "    accuracy                           0.62      9614\n",
      "   macro avg       0.47      0.56      0.48      9614\n",
      "weighted avg       0.73      0.62      0.65      9614\n",
      "\n",
      "\n",
      "Training Random Forest...\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, target_names=list(class_mapping.values()))\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'report': report,\n",
    "        'confusion_matrix': conf_matrix,\n",
    "        'training_time': training_time\n",
    "    }\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Training time: {training_time:.2f} seconds\")\n",
    "    print(f\"Classification Report:\\n{report}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=list(class_mapping.values()),\n",
    "                yticklabels=list(class_mapping.values()))\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'confusion_matrix_{name.replace(\" \", \"_\")}.png')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74666f38-70df-4973-91f5-2b200d53d9a6",
   "metadata": {},
   "source": [
    "Compare model accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135a3d03-3a89-4f86-9bff-0b1867b0bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "model_names = list(results.keys())\n",
    "accuracies = [results[name]['accuracy'] for name in model_names]\n",
    "\n",
    "plt.bar(model_names, accuracies)\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Model')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison.png')\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af516777-3908-4c02-9e2f-12417f07c27c",
   "metadata": {},
   "source": [
    "Identify the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1e7a44-dbf7-4933-973c-f9343791420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = max(results, key=lambda k: results[k]['accuracy'])\n",
    "print(f\"\\nBest model: {best_model_name} with accuracy {results[best_model_name]['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70594e4c-fd1d-4140-befc-6ebc895453f7",
   "metadata": {},
   "source": [
    "# Step 5: Hyperparameter Tuning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2746bfb-9e0b-4440-9dfa-59aa9275ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nStep 5: Tuning hyperparameters for the best model...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c39d6b7-bf65-43e3-b056-8c19ca499d87",
   "metadata": {},
   "source": [
    "Define parameter grid based on the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f44888a-9883-4180-8ed1-d37a7801838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model_name == 'Logistic Regression':\n",
    "    param_grid = {\n",
    "        'C': [0.1, 0.5, 1, 5, 10],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'class_weight': ['balanced', None]\n",
    "    }\n",
    "    model = LogisticRegression(max_iter=2000)\n",
    "elif best_model_name == 'Random Forest':\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "elif best_model_name == 'Linear SVM':\n",
    "    param_grid = {\n",
    "        'C': [0.1, 0.5, 1, 5, 10],\n",
    "        'loss': ['hinge', 'squared_hinge'],\n",
    "        'class_weight': ['balanced', None]\n",
    "    }\n",
    "    model = LinearSVC(max_iter=10000)\n",
    "elif best_model_name == 'Multinomial NB':\n",
    "    param_grid = {\n",
    "        'alpha': [0.01, 0.05, 0.1, 0.5, 1.0, 2.0]\n",
    "    }\n",
    "    model = MultinomialNB()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0199d955-f702-4674-9c91-f7be1363d12a",
   "metadata": {},
   "source": [
    "Perform grid search with cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db153e2-0fcb-4af8-9caa-f0247e959515",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Performing grid search for {best_model_name}...\")\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d787a38-dbe0-49f8-b0f2-ad9638d71746",
   "metadata": {},
   "source": [
    "Get best parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317ae60d-281e-411f-8d0a-19a93ed8a9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef1bacc-81b8-47e0-9fa0-3b49c7385954",
   "metadata": {},
   "source": [
    "Get the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaa966b-582f-4d52-9b95-8abd999ce955",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7fce1c-d5f4-4e86-95c8-2fc93af889dd",
   "metadata": {},
   "source": [
    "Evaluate the tuned model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb757e7-3e8b-4cb5-b7be-103d11c4f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test_tfidf)\n",
    "print(f\"Tuned model test accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred, target_names=list(class_mapping.values()))}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523aa01d-70d2-4a66-b7a2-88cde5679725",
   "metadata": {},
   "source": [
    "Plot confusion matrix for tuned model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53655c21-f8fb-46fe-a5f5-6563a38a2d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=list(class_mapping.values()),\n",
    "            yticklabels=list(class_mapping.values()))\n",
    "plt.title(f'Confusion Matrix - Tuned {best_model_name}')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_tuned_model.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac72802-6a62-4b3a-b932-52989d52731f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae05670-dd49-454c-99fa-f21f3f0c532b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1642f41-8734-4ce7-8e35-1bb21346b3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9683c8-fe9b-4f8d-b1f2-617c35dc167e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da98481d-a156-4cc7-957a-85f9ef078475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a0e5e-2982-43cf-bec8-85850de594d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f020d51-df6e-4c52-ae6a-769936820425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de29d138-8bfb-49ab-8b0f-4274a10d0cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
