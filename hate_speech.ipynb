{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "7131822e-45de-48ca-b6ba-e563d4151ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8991e7ab-9222-49eb-a933-103cbfee707e",
   "metadata": {},
   "source": [
    "# Step 1: Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de9d9d1-a34a-46a2-b7cd-59e652a060dc",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "fdcd1771-44c5-471e-a811-315f5348428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('HateSpeech_Kenya.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1307979a-2d9c-47af-981e-b448191a4844",
   "metadata": {},
   "source": [
    "Display basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "9eb0007b-9651-4116-aac1-85cc728023ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (48076, 5)\n",
      "Columns: ['hate_speech', 'offensive_language', 'neither', 'Class', 'Tweet']\n",
      "   hate_speech  offensive_language  neither  Class  \\\n",
      "0            0                   0        3      0   \n",
      "1            0                   0        3      0   \n",
      "2            0                   0        3      0   \n",
      "3            0                   0        3      0   \n",
      "4            0                   0        3      0   \n",
      "\n",
      "                                               Tweet  \n",
      "0  ['The political elite are in desperation. Ordi...  \n",
      "1  [\"Am just curious the only people who are call...  \n",
      "2  ['USERNAME_3 the area politicians are the one ...  \n",
      "3  ['War expected in Nakuru if something is not d...  \n",
      "4  ['USERNAME_4 tells kikuyus activists that they...  \n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bcd630-40be-49cf-9e64-6757c45dd053",
   "metadata": {},
   "source": [
    "Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "10d29cf1-75b9-4897-9690-d5fd426eac76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n",
      "hate_speech           0\n",
      "offensive_language    0\n",
      "neither               0\n",
      "Class                 0\n",
      "Tweet                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a081f5-cbfc-4a44-acd3-7d8c56377b47",
   "metadata": {},
   "source": [
    "Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "eee48ad1-724e-4e7f-89c7-9e4efe743ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution:\n",
      "Class\n",
      "0    36352\n",
      "1     8543\n",
      "2     3181\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_counts = df['Class'].value_counts()\n",
    "print(\"\\nClass distribution:\")\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209cfa14-b78f-4be0-a3f3-4c1880d4fb55",
   "metadata": {},
   "source": [
    "Map class values to readable labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "3cf63baa-9fcc-451c-8880-a16f2b1adca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    0: \"Neither\",\n",
    "    1: \"Offensive\",\n",
    "    2: \"Hate Speech\"\n",
    "}\n",
    "\n",
    "df['class_label'] = df['Class'].map(class_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a3f0a7-9305-4efa-b5cc-21f5c77e67c4",
   "metadata": {},
   "source": [
    "Visualize class distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "19f957a4-9d57-4a91-a506-00616bc3f3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='class_label', data=df)\n",
    "plt.title('Distribution of Classes')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Class')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_distribution.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c95365-8f5c-43d7-bd0f-98135913c16e",
   "metadata": {},
   "source": [
    "# Step 2: Text Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0520fd88-7012-461b-8458-b1d270899492",
   "metadata": {},
   "source": [
    "Download NLTK resources if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "dccb2bd1-8d52-44fd-946f-547d50ce67b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('punkt_tab')\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('wordnet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24879841-a80b-4ed2-8534-c563c0ab6f7e",
   "metadata": {},
   "source": [
    "Initialize lemmatizer and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "6422a1bd-5897-4ae9-8836-0d495e659d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and preprocess text data\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove the list formatting if present (specific to this dataset)\n",
    "    text = re.sub(r\"^\\['|'\\]$\", \"\", text)\n",
    "    text = text.replace(\"\\\\\\\"\", \"\")\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    \n",
    "    # Remove usernames (specific to this dataset)\n",
    "    text = re.sub(r'USERNAME_\\d+', '', text)\n",
    "    \n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and lemmatize\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words and len(token) > 2]\n",
    "    \n",
    "    # Rejoin tokens\n",
    "    cleaned_text = ' '.join(cleaned_tokens)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d821c9c-411c-417a-83a0-3a33d053f564",
   "metadata": {},
   "source": [
    "Apply preprocessing to the Tweet column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "386cd1f9-f560-4357-af53-d7de11880e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_text'] = df['Tweet'].apply(preprocess_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da01fde-3568-4092-992b-3756ea0608c5",
   "metadata": {},
   "source": [
    "Compare original and processed text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "9e8d2fd9-7412-4b36-aa2c-65b999a4f336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original vs Processed text samples:\n",
      "Original: ['The political elite are in desperation. Ordinary kalenjins are suspicious of kikuyu community']\n",
      "Processed: political elite desperation ordinary kalenjins suspicious kikuyu community\n",
      "\n",
      "Original: [\"Am just curious the only people who are calling him old and mad are Kikuyus and not Kalenjins and that's a good sign USERNAME_1 USERNAME_2\"]\n",
      "Processed: curious people calling old mad kikuyus kalenjins thats good sign username_ username_\n",
      "\n",
      "Original: ['USERNAME_3 the area politicians are the one to blame coz they r insiting local students n villagers to attack non kalenjins students']\n",
      "Processed: username_ area politician one blame coz insiting local student villager attack non kalenjins student\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOriginal vs Processed text samples:\")\n",
    "for i in range(3):\n",
    "    print(f\"Original: {df['Tweet'].iloc[i]}\")\n",
    "    print(f\"Processed: {df['processed_text'].iloc[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0d4093-ae7d-430d-b8e3-bf57835b962e",
   "metadata": {},
   "source": [
    "# Step 3: Feature Engineering and Data Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "a8a7232d-4e74-4478-87d8-2e8df6c69781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Creating features and splitting data...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 3: Creating features and splitting data...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456fc44c-d2ba-4f02-880e-1e38e6be0b88",
   "metadata": {},
   "source": [
    "Check for and remove empty processed texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "eed3b4cc-de45-49c0-9f9f-8a7e1b6109eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty texts after preprocessing: 9\n"
     ]
    }
   ],
   "source": [
    "empty_texts = df['processed_text'].str.strip() == ''\n",
    "print(f\"Number of empty texts after preprocessing: {sum(empty_texts)}\")\n",
    "df = df[~empty_texts].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beb4a02-3c34-4d1b-939b-70e39ae30742",
   "metadata": {},
   "source": [
    "Split data into features and target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "5235f6fd-acc9-40ba-8470-a873732480a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['processed_text']\n",
    "y = df['Class']  # Using the numerical class labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f58af39-e6a3-4d2e-b3c8-5f5ded8a1016",
   "metadata": {},
   "source": [
    "Split into training and testing sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "50152cd3-e14e-47b3-a1a5-483b8948a225",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3243b3d3-53ab-4fc1-9171-5659157bbe1a",
   "metadata": {},
   "source": [
    "Convert text to numerical features using TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "20708ab4-e6a2-4b0f-8d38-c0dcb9c5e5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (38453, 5000)\n",
      "Testing features shape: (9614, 5000)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, min_df=5)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"Training features shape: {X_train_tfidf.shape}\")\n",
    "print(f\"Testing features shape: {X_test_tfidf.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f167ce4b-6577-44a1-bfbb-2cbe9c7bc252",
   "metadata": {},
   "source": [
    "Save key vocabulary words for later reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "a0eb1372-9838-4b4b-adbb-c2ab6e07e240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top TF-IDF vocabulary words:\n",
      "['ababu', 'ability', 'able', 'abroad', 'absolute', 'absolutely', 'abt', 'abuse', 'abused', 'abusing', 'abusive', 'academic', 'accent', 'accept', 'acceptable', 'accepted', 'accepting', 'access', 'accident', 'according']\n"
     ]
    }
   ],
   "source": [
    "top_words = pd.DataFrame(tfidf_vectorizer.vocabulary_.items(), columns=['Word', 'Index'])\n",
    "top_words = top_words.sort_values('Index').head(20)\n",
    "print(\"\\nTop TF-IDF vocabulary words:\")\n",
    "print(top_words['Word'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9906e8aa-a74f-4422-8fd3-97d819213ed4",
   "metadata": {},
   "source": [
    "# Step 4: Model Building and Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "622e96b2-ea24-4552-803c-9d3488fb1718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Building and evaluating models...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 4: Building and evaluating models...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dfcc40-7b04-41c6-8a27-f2f1aa7435de",
   "metadata": {},
   "source": [
    "Define models to test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "95ad86af-e90f-437b-9687-19a4dae60b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, C=1, class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "    'Linear SVM': LinearSVC(C=1, class_weight='balanced', max_iter=10000),\n",
    "    'Multinomial NB': MultinomialNB(alpha=0.1)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a504dd4-389d-46d3-940a-57f0c5d3c332",
   "metadata": {},
   "source": [
    "Train and evaluate each model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "592f90cb-883d-423a-b2a1-e0d10e75ff57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.6158\n",
      "Training time: 1.63 seconds\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neither       0.88      0.66      0.76      7269\n",
      "   Offensive       0.30      0.42      0.35      1709\n",
      " Hate Speech       0.23      0.61      0.33       636\n",
      "\n",
      "    accuracy                           0.62      9614\n",
      "   macro avg       0.47      0.56      0.48      9614\n",
      "weighted avg       0.73      0.62      0.65      9614\n",
      "\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.7565\n",
      "Training time: 94.07 seconds\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neither       0.77      0.97      0.86      7269\n",
      "   Offensive       0.44      0.08      0.13      1709\n",
      " Hate Speech       0.42      0.13      0.19       636\n",
      "\n",
      "    accuracy                           0.76      9614\n",
      "   macro avg       0.54      0.39      0.40      9614\n",
      "weighted avg       0.69      0.76      0.69      9614\n",
      "\n",
      "\n",
      "Training Linear SVM...\n",
      "Linear SVM Accuracy: 0.6952\n",
      "Training time: 0.73 seconds\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neither       0.84      0.81      0.82      7269\n",
      "   Offensive       0.34      0.30      0.32      1709\n",
      " Hate Speech       0.26      0.45      0.33       636\n",
      "\n",
      "    accuracy                           0.70      9614\n",
      "   macro avg       0.48      0.52      0.49      9614\n",
      "weighted avg       0.71      0.70      0.70      9614\n",
      "\n",
      "\n",
      "Training Multinomial NB...\n",
      "Multinomial NB Accuracy: 0.7594\n",
      "Training time: 0.02 seconds\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neither       0.77      0.99      0.86      7269\n",
      "   Offensive       0.48      0.05      0.09      1709\n",
      " Hate Speech       0.46      0.04      0.08       636\n",
      "\n",
      "    accuracy                           0.76      9614\n",
      "   macro avg       0.57      0.36      0.34      9614\n",
      "weighted avg       0.70      0.76      0.67      9614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, target_names=list(class_mapping.values()))\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'report': report,\n",
    "        'confusion_matrix': conf_matrix,\n",
    "        'training_time': training_time\n",
    "    }\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Training time: {training_time:.2f} seconds\")\n",
    "    print(f\"Classification Report:\\n{report}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=list(class_mapping.values()),\n",
    "                yticklabels=list(class_mapping.values()))\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'confusion_matrix_{name.replace(\" \", \"_\")}.png')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74666f38-70df-4973-91f5-2b200d53d9a6",
   "metadata": {},
   "source": [
    "Compare model accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "135a3d03-3a89-4f86-9bff-0b1867b0bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "model_names = list(results.keys())\n",
    "accuracies = [results[name]['accuracy'] for name in model_names]\n",
    "\n",
    "plt.bar(model_names, accuracies)\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Model')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison.png')\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af516777-3908-4c02-9e2f-12417f07c27c",
   "metadata": {},
   "source": [
    "Identify the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "6d1e7a44-dbf7-4933-973c-f9343791420b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model: Multinomial NB with accuracy 0.7594\n"
     ]
    }
   ],
   "source": [
    "best_model_name = max(results, key=lambda k: results[k]['accuracy'])\n",
    "print(f\"\\nBest model: {best_model_name} with accuracy {results[best_model_name]['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70594e4c-fd1d-4140-befc-6ebc895453f7",
   "metadata": {},
   "source": [
    "# Step 5: Hyperparameter Tuning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "c2746bfb-9e0b-4440-9dfa-59aa9275ecdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5: Tuning hyperparameters for the best model...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 5: Tuning hyperparameters for the best model...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c39d6b7-bf65-43e3-b056-8c19ca499d87",
   "metadata": {},
   "source": [
    "Define parameter grid based on the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "7f44888a-9883-4180-8ed1-d37a7801838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model_name == 'Logistic Regression':\n",
    "    param_grid = {\n",
    "        'C': [0.1, 0.5, 1, 5, 10],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'class_weight': ['balanced', None]\n",
    "    }\n",
    "    model = LogisticRegression(max_iter=2000)\n",
    "elif best_model_name == 'Random Forest':\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "elif best_model_name == 'Linear SVM':\n",
    "    param_grid = {\n",
    "        'C': [0.1, 0.5, 1, 5, 10],\n",
    "        'loss': ['hinge', 'squared_hinge'],\n",
    "        'class_weight': ['balanced', None]\n",
    "    }\n",
    "    model = LinearSVC(max_iter=10000)\n",
    "elif best_model_name == 'Multinomial NB':\n",
    "    param_grid = {\n",
    "        'alpha': [0.01, 0.05, 0.1, 0.5, 1.0, 2.0]\n",
    "    }\n",
    "    model = MultinomialNB()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0199d955-f702-4674-9c91-f7be1363d12a",
   "metadata": {},
   "source": [
    "Perform grid search with cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "6db153e2-0fcb-4af8-9caa-f0247e959515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search for Multinomial NB...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=MultinomialNB(), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.01, 0.05, 0.1, 0.5, 1.0, 2.0]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=MultinomialNB(), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.01, 0.05, 0.1, 0.5, 1.0, 2.0]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: MultinomialNB</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB(alpha=0.01)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB(alpha=0.01)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MultinomialNB(), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.01, 0.05, 0.1, 0.5, 1.0, 2.0]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Performing grid search for {best_model_name}...\")\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d787a38-dbe0-49f8-b0f2-ad9638d71746",
   "metadata": {},
   "source": [
    "Get best parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "317ae60d-281e-411f-8d0a-19a93ed8a9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 0.01}\n",
      "Best cross-validation accuracy: 0.7581\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef1bacc-81b8-47e0-9fa0-3b49c7385954",
   "metadata": {},
   "source": [
    "Get the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "ceaa966b-582f-4d52-9b95-8abd999ce955",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7fce1c-d5f4-4e86-95c8-2fc93af889dd",
   "metadata": {},
   "source": [
    "Evaluate the tuned model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "bbb757e7-3e8b-4cb5-b7be-103d11c4f293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned model test accuracy: 0.7588\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neither       0.77      0.99      0.86      7269\n",
      "   Offensive       0.47      0.05      0.09      1709\n",
      " Hate Speech       0.46      0.05      0.09       636\n",
      "\n",
      "    accuracy                           0.76      9614\n",
      "   macro avg       0.56      0.36      0.35      9614\n",
      "weighted avg       0.69      0.76      0.67      9614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test_tfidf)\n",
    "print(f\"Tuned model test accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred, target_names=list(class_mapping.values()))}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523aa01d-70d2-4a66-b7a2-88cde5679725",
   "metadata": {},
   "source": [
    "Plot confusion matrix for tuned model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "53655c21-f8fb-46fe-a5f5-6563a38a2d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=list(class_mapping.values()),\n",
    "            yticklabels=list(class_mapping.values()))\n",
    "plt.title(f'Confusion Matrix - Tuned {best_model_name}')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_tuned_model.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbd3848-f092-49d1-afb0-744b0ef7f8eb",
   "metadata": {},
   "source": [
    "# Step 6: Feature Importance Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "3ae05670-dd49-454c-99fa-f21f3f0c532b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 6: Analyzing feature importance...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 6: Analyzing feature importance...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e94222-f7ec-4826-84de-61b07ffc6bf3",
   "metadata": {},
   "source": [
    "Get feature names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "9b9683c8-fe9b-4f8d-b1f2-617c35dc167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1504149-8753-47be-9648-596386928b20",
   "metadata": {},
   "source": [
    "For models that support feature importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "812a0e5e-2982-43cf-bec8-85850de594d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(best_model, 'coef_'):\n",
    "    # For models like Logistic Regression, LinearSVC\n",
    "    \n",
    "    # For each class, find the most important words\n",
    "    for i, class_label in enumerate(sorted(class_mapping.keys())):\n",
    "        # Get top words for this class\n",
    "        if len(best_model.coef_.shape) > 1:  # Multi-class\n",
    "            top_indices = np.argsort(best_model.coef_[i])[-20:]\n",
    "            top_features = [feature_names[j] for j in top_indices]\n",
    "            top_weights = [best_model.coef_[i][j] for j in top_indices]\n",
    "        else:  # Binary classification\n",
    "            top_indices = np.argsort(best_model.coef_[0])[-20:]\n",
    "            top_features = [feature_names[j] for j in top_indices]\n",
    "            top_weights = [best_model.coef_[0][j] for j in top_indices]\n",
    "        \n",
    "        # Plot feature importance\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.barh(range(len(top_features)), top_weights[-1::-1])\n",
    "        plt.yticks(range(len(top_features)), [top_features[i] for i in range(len(top_features)-1, -1, -1)])\n",
    "        plt.title(f'Top 20 Features for Class: {class_mapping[class_label]}')\n",
    "        plt.xlabel('Weight')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'feature_importance_class_{class_label}.png')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"\\nTop 20 words for class '{class_mapping[class_label]}':\")\n",
    "        for word, weight in zip(top_features[-1::-1], top_weights[-1::-1]):\n",
    "            print(f\"{word}: {weight:.4f}\")\n",
    "\n",
    "elif hasattr(best_model, 'feature_importances_'):\n",
    "    # For Random Forest\n",
    "    top_indices = np.argsort(best_model.feature_importances_)[-20:]\n",
    "    top_features = [feature_names[i] for i in top_indices]\n",
    "    top_weights = [best_model.feature_importances_[i] for i in top_indices]\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(range(len(top_features)), top_weights[-1::-1])\n",
    "    plt.yticks(range(len(top_features)), [top_features[i] for i in range(len(top_features)-1, -1, -1)])\n",
    "    plt.title('Top 20 Features Across All Classes')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance_overall.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\nTop 20 most important words across all classes:\")\n",
    "    for word, weight in zip(top_features[-1::-1], top_weights[-1::-1]):\n",
    "        print(f\"{word}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4bdd26-201f-44ab-9793-a3f415a769e2",
   "metadata": {},
   "source": [
    "# Step 7: Error Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "de29d138-8bfb-49ab-8b0f-4274a10d0cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 7: Analyzing misclassified examples...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 7: Analyzing misclassified examples...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182a2193-6346-4d4a-9411-ad75eb54595a",
   "metadata": {},
   "source": [
    "Get predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "bede9a99-e4df-44ae-aef6-47b9da82146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test_tfidf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21b8f47-b30b-4cf5-b986-0dd03c5b7f3e",
   "metadata": {},
   "source": [
    "Find misclassified examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "65c96da7-1179-48f0-832b-f86f1ea8dc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of misclassified examples: 2319\n"
     ]
    }
   ],
   "source": [
    "misclassified_indices = np.where(y_pred != y_test.values)[0]\n",
    "print(f\"Number of misclassified examples: {len(misclassified_indices)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f06361f-05b5-4ca9-b85d-aeba3b59e21a",
   "metadata": {},
   "source": [
    "Create a DataFrame for misclassified examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "2ce73b75-c633-498b-83de-5bdd880a99a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample misclassified examples:\n",
      "\n",
      "Text: kikuyus like israelite never change matter wat say kikuyus\n",
      "True label: Offensive\n",
      "Predicted label: Neither\n",
      "\n",
      "Text: cant withdraw detail presidential candidate mate wrong caretaker govt noreformsnoelections\n",
      "True label: Offensive\n",
      "Predicted label: Neither\n",
      "\n",
      "Text: put nob head authority get fck town luolivesmatter\n",
      "True label: Offensive\n",
      "Predicted label: Neither\n",
      "\n",
      "Text: kill democracy like nyanza behind inept odinga political future follow kikuyus\n",
      "True label: Hate Speech\n",
      "Predicted label: Neither\n",
      "\n",
      "Text: wakikuyu tumeamua baba hawa walevi wametuzoea sana\n",
      "True label: Offensive\n",
      "Predicted label: Neither\n"
     ]
    }
   ],
   "source": [
    "if len(misclassified_indices) > 0:\n",
    "    misclassified_df = pd.DataFrame({\n",
    "        'Text': X_test.iloc[misclassified_indices].values,\n",
    "        'True_Label': [class_mapping[y] for y in y_test.iloc[misclassified_indices].values],\n",
    "        'Predicted_Label': [class_mapping[y] for y in y_pred[misclassified_indices]]\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    misclassified_df.to_csv('misclassified_examples.csv', index=False)\n",
    "    \n",
    "    # Display some misclassified examples\n",
    "    print(\"\\nSample misclassified examples:\")\n",
    "    for i in range(min(5, len(misclassified_indices))):\n",
    "        idx = misclassified_indices[i]\n",
    "        text = X_test.iloc[idx]\n",
    "        true_label = class_mapping[y_test.iloc[idx]]\n",
    "        pred_label = class_mapping[y_pred[idx]]\n",
    "        \n",
    "        print(f\"\\nText: {text}\")\n",
    "        print(f\"True label: {true_label}\")\n",
    "        print(f\"Predicted label: {pred_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0d3e56-4814-40d0-82ee-7f276fdddf3f",
   "metadata": {},
   "source": [
    "# Step 8: Save the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "263857c1-c9f3-4473-a831-e7b9eaf4be09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 8: Saving the model...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 8: Saving the model...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf1f29-bda2-4c54-a77d-9fced41918c5",
   "metadata": {},
   "source": [
    "Create a simple model info dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "5468e28e-ccf4-4dff-b487-df17240010ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = {\n",
    "    'model_type': best_model_name,\n",
    "    'accuracy': accuracy_score(y_test, y_pred),\n",
    "    'class_mapping': class_mapping,\n",
    "    'creation_date': time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    'feature_count': X_train_tfidf.shape[1]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c624d21-8cca-42f5-81c3-ba278866b99f",
   "metadata": {},
   "source": [
    "\n",
    "Save the model and necessary components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "b72b8447-cf4c-4af4-9558-903f7f1ca466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "with open('hate_speech_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "\n",
    "with open('model_info.pkl', 'wb') as f:\n",
    "    pickle.dump(model_info, f)\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bc1391-28cd-4f7d-8edf-45a046a98a8b",
   "metadata": {},
   "source": [
    "# Step 9: Create a Function for Classifying New Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "119079a6-3cd8-4bbc-ab3a-a18a43cd8fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 9: Creating classification function...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 9: Creating classification function...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "4ef3d2f5-7289-4e12-b9af-e4444f066120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_hate_speech(text):\n",
    "    \"\"\"\n",
    "    Classify a given text as Hate Speech, Offensive, or Neither\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to classify\n",
    "        \n",
    "    Returns:\n",
    "        str: The predicted class label\n",
    "        float: Confidence score (if available)\n",
    "    \"\"\"\n",
    "    # Load the model and vectorizer\n",
    "    with open('hate_speech_model.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    with open('tfidf_vectorizer.pkl', 'rb') as f:\n",
    "        vectorizer = pickle.load(f)\n",
    "    \n",
    "    with open('model_info.pkl', 'rb') as f:\n",
    "        model_info = pickle.load(f)\n",
    "    \n",
    "    # Preprocess the text\n",
    "    processed_text = preprocess_text(text)\n",
    "    \n",
    "    # Transform the text\n",
    "    text_tfidf = vectorizer.transform([processed_text])\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(text_tfidf)[0]\n",
    "    \n",
    "    # Get confidence score if available\n",
    "    confidence = None\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        probas = model.predict_proba(text_tfidf)[0]\n",
    "        confidence = max(probas)\n",
    "    \n",
    "    # Convert to label\n",
    "    predicted_label = model_info['class_mapping'][prediction]\n",
    "    \n",
    "    if confidence is not None:\n",
    "        return predicted_label, confidence\n",
    "    else:\n",
    "        return predicted_label, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639e2a0-84da-4dbd-a47b-d00e58a411a2",
   "metadata": {},
   "source": [
    "Test the function with some examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "a3d47e11-d2d6-4e87-b860-3e759a14c035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing classification function with example texts:\n",
      "Text: 'I love how diverse our community is!'\n",
      "Prediction: 'Neither' (Confidence: 0.83)\n",
      "\n",
      "Text: 'Those people should go back to where they came from'\n",
      "Prediction: 'Neither' (Confidence: 0.78)\n",
      "\n",
      "Text: 'This politician is completely useless and incompetent'\n",
      "Prediction: 'Neither' (Confidence: 0.58)\n",
      "\n",
      "Text: 'The Kikuyu people are ruining this country'\n",
      "Prediction: 'Neither' (Confidence: 0.65)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting classification function with example texts:\")\n",
    "sample_texts = [\n",
    "    \"I love how diverse our community is!\",\n",
    "    \"Those people should go back to where they came from\",\n",
    "    \"This politician is completely useless and incompetent\",\n",
    "    \"The Kikuyu people are ruining this country\"\n",
    "]\n",
    "\n",
    "for text in sample_texts:\n",
    "    prediction, confidence = classify_hate_speech(text)\n",
    "    confidence_str = f\" (Confidence: {confidence:.2f})\" if confidence else \"\"\n",
    "    print(f\"Text: '{text}'\")\n",
    "    print(f\"Prediction: '{prediction}'{confidence_str}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "873f749a-1eaa-40fc-afbd-5697efbd7d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Hate speech classification model complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Done! Hate speech classification model complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f0a0b-7fa8-44eb-9d99-020cd8875bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
